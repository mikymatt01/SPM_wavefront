{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and define useful staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: Strong and Weak analysis of scatter and gather impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "diagonal_sg_mpi_pd = pd.read_csv(\"../test_mpi/wavefront_diagonal_sg_mpi/20241022_144027/wavefront_runtimes.csv\")\n",
    "\n",
    "diagonal_allg_mpi_pd = pd.read_csv(\"../test_mpi/wavefront_diagonal_allg_mpi/20241021_000232/wavefront_runtimes.csv\")\n",
    "triangles_allg_mpi_pd = pd.read_csv(\"../test_mpi/wavefront_triangles_allg_mpi/20241021_021044/wavefront_runtimes.csv\")\n",
    "\n",
    "diagonal_ff_pd = pd.read_csv(\"../test_fastflow/wavefront_diagonal_ff/20241019_214949/wavefront_runtimes.csv\")\n",
    "triangles_ff_pd = pd.read_csv(\"../test_fastflow/wavefront_triangles_ff/20241019_215007/wavefront_runtimes.csv\")\n",
    "\n",
    "diagonal_pd = pd.read_csv(\"../test_sequential/wavefront_diagonal/20241020_164223/wavefront_runtimes.csv\")\n",
    "triangles_pd = pd.read_csv(\"../test_sequential/wavefront_triangles/20241020_164245/wavefront_runtimes.csv\")\n",
    "\n",
    "diagonal_sg_mpi = diagonal_sg_mpi_pd.to_dict(orient='records')\n",
    "\n",
    "diagonal_allg_mpi = diagonal_allg_mpi_pd.to_dict(orient='records')\n",
    "triangles_allg_mpi = triangles_allg_mpi_pd.to_dict(orient='records')\n",
    "\n",
    "diagonal_ff = diagonal_ff_pd.to_dict(orient='records')\n",
    "triangles_ff = triangles_ff_pd.to_dict(orient='records')\n",
    "\n",
    "diagonal_seq = diagonal_pd.to_dict(orient='records')\n",
    "triangles_seq = triangles_pd.to_dict(orient='records')\n",
    "\n",
    "print(diagonal_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [2048, 2896, 4096, 5793, 8192]\n",
    "processes = [1, 2, 4, 8, 16, 32]\n",
    "\n",
    "class CSVKeys:\n",
    "     name = 'Version'\n",
    "     size = 'Matrix size'\n",
    "     workers = 'Workers number'\n",
    "     triangles = 'Triangles number'\n",
    "     runtime = 'Time'\n",
    "     value ='Value'\n",
    "\n",
    "class DATAKeys:\n",
    "        processors = 'processors'\n",
    "        runtime_diagonal ='runtime_diagonal_par'\n",
    "        runtime_triangle ='runtime_triangle_par'\n",
    "        T_seq = 'T_seq'\n",
    "        path = 'path'\n",
    "        size = 'size'\n",
    "\n",
    "class Version:\n",
    "     seq = 'sequential'\n",
    "     mpi = 'mpi'\n",
    "     ff = 'fastflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_analysis(\n",
    "    processors,\n",
    "    runtime,\n",
    "    cost,\n",
    "    speedup,\n",
    "    efficiency,\n",
    "    title,\n",
    "    runtime2,\n",
    "    cost2,\n",
    "    speedup2,\n",
    "    efficiency2,\n",
    "    title2,\n",
    "    filename\n",
    "):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    def add_table(ax, values1, values2, label1, label2):\n",
    "        cell_text = [values1, values2]\n",
    "        row_labels = [label1, label2]\n",
    "        table = ax.table(cellText=cell_text,\n",
    "                        rowLabels=row_labels,\n",
    "                        cellLoc='center',\n",
    "                        rowLoc='center',\n",
    "                        loc='bottom',\n",
    "                        bbox=[0, -0.4, 1, 0.2])\n",
    "        table.scale(1, 1.2)\n",
    "\n",
    "    axs[0, 0].plot(processors, runtime, color='orange', label=f'Runtime {title}')\n",
    "    axs[0, 0].plot(processors, runtime2, color='blue', label=f'Runtime {title2}', linestyle='--')\n",
    "    axs[0, 0].set_title(f'Runtime (ms)')\n",
    "    axs[0, 0].set_xlabel('Processors (p)')\n",
    "    axs[0, 0].set_ylabel('Runtime (ms)')\n",
    "    axs[0, 0].grid(True)\n",
    "    axs[0, 0].legend()\n",
    "    add_table(axs[0, 0], runtime, runtime2, f'Runtime {title} (ms)', f'Runtime {title2} (ms)')\n",
    "\n",
    "    axs[0, 1].plot(processors, cost, color='orange', label=f'Cost {title}')\n",
    "    axs[0, 1].plot(processors, cost2, color='blue', label=f'Cost {title2}', linestyle='--')\n",
    "    axs[0, 1].set_title(f'Cost')\n",
    "    axs[0, 1].set_xlabel('Processors (p)')\n",
    "    axs[0, 1].set_ylabel('Cost')\n",
    "    axs[0, 1].grid(True)\n",
    "    axs[0, 1].legend()\n",
    "    add_table(axs[0, 1], cost, cost2, f'Cost {title}', f'Cost {title2}')\n",
    "\n",
    "    axs[1, 0].plot(processors, speedup, color='orange', label=f'Speedup {title}')\n",
    "    axs[1, 0].plot(processors, speedup2, color='blue', label=f'Speedup {title2}', linestyle='--')\n",
    "    axs[1, 0].set_title(f'Speedup')\n",
    "    axs[1, 0].set_xlabel('Processors (p)')\n",
    "    axs[1, 0].set_ylabel('Speedup')\n",
    "    axs[1, 0].grid(True)\n",
    "    axs[1, 0].legend()\n",
    "    add_table(axs[1, 0], speedup, speedup2, f'Speedup {title}', f'Speedup {title2}')\n",
    "\n",
    "    axs[1, 1].bar(processors, efficiency, color='orange', label=f'Efficiency {title}', width=0.4, align='center')\n",
    "    axs[1, 1].bar(np.array(processors) + 0.4, efficiency2, color='blue', label=f'Efficiency {title2}', width=0.4, align='center')\n",
    "    axs[1, 1].set_title('Efficiency (in %)')\n",
    "    axs[1, 1].set_xlabel('Processors (p)')\n",
    "    axs[1, 1].set_ylabel('Efficiency (%)')\n",
    "    axs[1, 1].grid(True)\n",
    "    axs[1, 1].legend()\n",
    "    add_table(axs[1, 1], efficiency, efficiency2, f'Efficiency {title}', f'Efficiency {title2}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_single_analysis(\n",
    "    processors,\n",
    "    runtime,\n",
    "    cost,\n",
    "    speedup,\n",
    "    efficiency,\n",
    "    title,\n",
    "    filename\n",
    "):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    def add_table(ax, values1, label1):\n",
    "        cell_text = [values1]\n",
    "        row_labels = [label1]\n",
    "        table = ax.table(cellText=cell_text,\n",
    "                        rowLabels=row_labels,\n",
    "                        cellLoc='center',\n",
    "                        rowLoc='center',\n",
    "                        loc='bottom',\n",
    "                        bbox=[0, -0.4, 1, 0.2])\n",
    "        table.scale(1, 1.2)\n",
    "\n",
    "    axs[0, 0].plot(processors, runtime, color='orange', label=f'Runtime {title}')\n",
    "    axs[0, 0].set_title(f'Runtime (ms)')\n",
    "    axs[0, 0].set_xlabel('Processors (p)')\n",
    "    axs[0, 0].set_ylabel('Runtime (ms)')\n",
    "    axs[0, 0].grid(True)\n",
    "    axs[0, 0].legend()\n",
    "    add_table(axs[0, 0], runtime, f'Runtime {title} (ms)')\n",
    "\n",
    "    axs[0, 1].plot(processors, cost, color='orange', label=f'Cost {title}')\n",
    "    axs[0, 1].set_title(f'Cost')\n",
    "    axs[0, 1].set_xlabel('Processors (p)')\n",
    "    axs[0, 1].set_ylabel('Cost')\n",
    "    axs[0, 1].grid(True)\n",
    "    axs[0, 1].legend()\n",
    "    add_table(axs[0, 1], cost, f'Cost {title}')\n",
    "\n",
    "    axs[1, 0].plot(processors, speedup, color='orange', label=f'Speedup {title}')\n",
    "    axs[1, 0].set_title(f'Speedup')\n",
    "    axs[1, 0].set_xlabel('Processors (p)')\n",
    "    axs[1, 0].set_ylabel('Speedup')\n",
    "    axs[1, 0].grid(True)\n",
    "    axs[1, 0].legend()\n",
    "    add_table(axs[1, 0], speedup, f'Speedup {title}')\n",
    "\n",
    "    axs[1, 1].bar(processors, efficiency, color='orange', label=f'Efficiency {title}', width=0.4, align='center')\n",
    "    axs[1, 1].set_title('Efficiency (in %)')\n",
    "    axs[1, 1].set_xlabel('Processors (p)')\n",
    "    axs[1, 1].set_ylabel('Efficiency (%)')\n",
    "    axs[1, 1].grid(True)\n",
    "    axs[1, 1].legend()\n",
    "    add_table(axs[1, 1], efficiency, f'Efficiency {title}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(strong_scalability_item):\n",
    "    processors = strong_scalability_item[DATAKeys.processors]\n",
    "    runtime_diag_par = strong_scalability_item[DATAKeys.runtime_diagonal]\n",
    "    runtime_tria_par = strong_scalability_item[DATAKeys.runtime_triangle]\n",
    "    T_seq = strong_scalability_item[DATAKeys.T_seq]\n",
    "\n",
    "    speedup_diag = []\n",
    "    speedup_tria = []\n",
    "    if isinstance(T_seq, list):\n",
    "        speedup_diag = [round(t / r, 2) for t, r in zip(T_seq, runtime_diag_par)]\n",
    "        speedup_tria = [round(t / r, 2) for t, r in zip(T_seq, runtime_tria_par)]\n",
    "    else:\n",
    "        speedup_diag = [round(T_seq / r, 2) for r in runtime_diag_par]\n",
    "        speedup_tria = [round(T_seq / r, 2) for r in runtime_tria_par]\n",
    "\n",
    "\n",
    "    cost_diag = [r * p for r, p in zip(runtime_diag_par, processors)]\n",
    "    cost_tria = [r * p for r, p in zip(runtime_tria_par, processors)]\n",
    "\n",
    "\n",
    "    efficiency_diag = [round(100 * s / p, 2) for s, p in zip(speedup_diag, processors)]\n",
    "    efficiency_tria = [round(100 * s / p, 2) for s, p in zip(speedup_tria, processors)]\n",
    "\n",
    "    return (\n",
    "        runtime_diag_par,\n",
    "        speedup_diag,\n",
    "        cost_diag,\n",
    "        efficiency_diag,\n",
    "        runtime_tria_par,\n",
    "        speedup_tria,\n",
    "        cost_tria,\n",
    "        efficiency_tria,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStrongScalabilityData(\n",
    "        size,\n",
    "        processes,\n",
    "        diagonal_seq,\n",
    "        triangles_seq,\n",
    "        diagonal_par,\n",
    "        triangles_par,\n",
    "        dir=\"strong_scalability_plots\"\n",
    "    ):\n",
    "    strong_scalability_data = []\n",
    "    for s in size:\n",
    "        diagonal_seq_runtime = [row[CSVKeys.runtime] for row in diagonal_seq if row[CSVKeys.size] == s]\n",
    "        triangles_seq_runtime = [row[CSVKeys.runtime] for row in triangles_seq if row[CSVKeys.size] == s]\n",
    "\n",
    "        diagonal_par_runtime = [row[CSVKeys.runtime] for row in diagonal_par if row[CSVKeys.size] == s]\n",
    "        triangles_par_runtime = [row[CSVKeys.runtime] for row in triangles_par if row[CSVKeys.size] == s]\n",
    "\n",
    "        t_seq = min(min(diagonal_seq_runtime), min(triangles_seq_runtime))\n",
    "        \n",
    "        strong_scalability_data.append({\n",
    "            DATAKeys.processors: processes,\n",
    "            DATAKeys.runtime_diagonal: diagonal_par_runtime,\n",
    "            DATAKeys.runtime_triangle: triangles_par_runtime,\n",
    "            DATAKeys.T_seq: t_seq,\n",
    "            DATAKeys.path: f'./{dir}/{s}/',\n",
    "            DATAKeys.size: [s] * len(triangles_par_runtime),\n",
    "        })\n",
    "    return strong_scalability_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Scaling Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_scalability_data_ff = getStrongScalabilityData(\n",
    "    size,\n",
    "    processes,\n",
    "    diagonal_seq,\n",
    "    triangles_seq,\n",
    "    diagonal_ff,\n",
    "    triangles_ff,\n",
    "    dir=\"strong_scalability_plots_ff\"\n",
    ")\n",
    "\n",
    "strong_scalability_data_mpi = getStrongScalabilityData(\n",
    "    size,\n",
    "    processes,\n",
    "    diagonal_seq,\n",
    "    triangles_seq,\n",
    "    diagonal_allg_mpi,\n",
    "    triangles_allg_mpi,\n",
    "    dir=\"strong_scalability_plots_allg_mpi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastflow Strong scaling plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strong_scalability_item in strong_scalability_data_ff:\n",
    "    runtime_diag_par, speedup_diag, cost_diag, efficiency_diag, runtime_tria_par,speedup_tria, cost_tria, efficiency_tria = computeMetrics(strong_scalability_item)\n",
    "    print(strong_scalability_item[DATAKeys.size])\n",
    "    os.system(f'mkdir -p {strong_scalability_item[DATAKeys.path]}')\n",
    "    plot_analysis(\n",
    "        strong_scalability_item[DATAKeys.processors],\n",
    "        runtime_diag_par,\n",
    "        cost_diag,\n",
    "        speedup_diag,\n",
    "        efficiency_diag,\n",
    "        'ff diagonals',\n",
    "        runtime_tria_par,\n",
    "        cost_tria,\n",
    "        speedup_tria,\n",
    "        efficiency_tria,\n",
    "        'ff triangles',\n",
    "        f'{strong_scalability_item[DATAKeys.path]}/analysis'\n",
    "    ) \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPI Strong scaling plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strong_scalability_item in strong_scalability_data_mpi:\n",
    "    runtime_diag_par, speedup_diag, cost_diag, efficiency_diag, runtime_tria_par,speedup_tria, cost_tria, efficiency_tria = computeMetrics(strong_scalability_item)\n",
    "    print(strong_scalability_item[DATAKeys.size])\n",
    "    os.system(f'mkdir -p {strong_scalability_item[DATAKeys.path]}')\n",
    "    plot_analysis(\n",
    "        strong_scalability_item[DATAKeys.processors],\n",
    "        runtime_diag_par,\n",
    "        cost_diag,\n",
    "        speedup_diag,\n",
    "        efficiency_diag,\n",
    "        'ff diagonals',\n",
    "        runtime_tria_par,\n",
    "        cost_tria,\n",
    "        speedup_tria,\n",
    "        efficiency_tria,\n",
    "        'ff triangles',\n",
    "        f'{strong_scalability_item[DATAKeys.path]}/analysis'\n",
    "    ) \n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Scaling Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_ff_runtimes = []\n",
    "diagonal_ff_runtimes = []\n",
    "seq_runtimes = []\n",
    "\n",
    "for s, p in zip(size, processes[1:]):\n",
    "\n",
    "    diag_seq_runtime = [runtime[CSVKeys.runtime] for runtime in diagonal_seq if runtime[CSVKeys.size] == s]\n",
    "    tria_seq_runtime = [runtime[CSVKeys.runtime] for runtime in triangles_seq if runtime[CSVKeys.size] == s]\n",
    "    diagonal_ff_runtime = [runtime[CSVKeys.runtime] for runtime in diagonal_ff if runtime[CSVKeys.size] == s and runtime[CSVKeys.workers] == p]\n",
    "    triangle_ff_runtime = [runtime[CSVKeys.runtime] for runtime in triangles_ff if runtime[CSVKeys.size] == s and runtime[CSVKeys.workers] == p]\n",
    "    \n",
    "    diagonal_ff_runtimes.append(diagonal_ff_runtime[0])\n",
    "    triangle_ff_runtimes.append(triangle_ff_runtime[0])\n",
    "    seq_runtimes.append(min(min(diag_seq_runtime), min(tria_seq_runtime)))\n",
    "\n",
    "weak_scalability_data_ff = {\n",
    "    DATAKeys.processors: processes[1:],\n",
    "    DATAKeys.runtime_diagonal: diagonal_ff_runtimes,\n",
    "    DATAKeys.runtime_triangle: triangle_ff_runtimes,\n",
    "    DATAKeys.T_seq: seq_runtimes,\n",
    "    DATAKeys.path: f'./weak_scalability_plots_ff/',\n",
    "    DATAKeys.size: size\n",
    "}\n",
    "\n",
    "triangle_allg_mpi_runtimes = []\n",
    "diagonal_allg_mpi_runtimes = []\n",
    "seq_runtimes = []\n",
    "\n",
    "for s, p in zip(size, processes[1:]):\n",
    "\n",
    "    diag_seq_runtime = [runtime[CSVKeys.runtime] for runtime in diagonal_seq if runtime[CSVKeys.size] == s]\n",
    "    tria_seq_runtime = [runtime[CSVKeys.runtime] for runtime in triangles_seq if runtime[CSVKeys.size] == s]\n",
    "    diagonal_allg_mpi_runtime = [runtime[CSVKeys.runtime] for runtime in diagonal_allg_mpi if runtime[CSVKeys.size] == s and runtime[CSVKeys.workers] == p]\n",
    "    triangle_allg_mpi_runtime = [runtime[CSVKeys.runtime] for runtime in triangles_allg_mpi if runtime[CSVKeys.size] == s and runtime[CSVKeys.workers] == p]\n",
    "    \n",
    "    diagonal_allg_mpi_runtimes.append(diagonal_allg_mpi_runtime[0])\n",
    "    triangle_allg_mpi_runtimes.append(triangle_allg_mpi_runtime[0])\n",
    "    print(tria_seq_runtime)\n",
    "    seq_runtimes.append(min(min(diag_seq_runtime), min(tria_seq_runtime)))\n",
    "\n",
    "weak_scalability_data_mpi = {\n",
    "    DATAKeys.processors: processes[1:],\n",
    "    DATAKeys.runtime_diagonal: diagonal_allg_mpi_runtimes,\n",
    "    DATAKeys.runtime_triangle: triangle_allg_mpi_runtimes,\n",
    "    DATAKeys.T_seq: seq_runtimes,\n",
    "    DATAKeys.path: f'./weak_scalability_plots_allg_mpi/',\n",
    "    DATAKeys.size: size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FF Weak Scalability Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_diag_par, speedup_diag, cost_diag, efficiency_diag, runtime_tria_par, speedup_tria, cost_tria, efficiency_tria = computeMetrics(weak_scalability_data_ff)\n",
    "os.system(f\"mkdir -p {weak_scalability_data_ff[DATAKeys.path]}\")\n",
    "\n",
    "plot_analysis(\n",
    "    weak_scalability_data_ff[DATAKeys.processors],\n",
    "    runtime_diag_par,\n",
    "    cost_diag,\n",
    "    speedup_diag,\n",
    "    efficiency_diag,\n",
    "    'ff diagonals',\n",
    "    runtime_tria_par,\n",
    "    cost_tria,\n",
    "    speedup_tria,\n",
    "    efficiency_tria,\n",
    "    'ff triangles',\n",
    "    f'{weak_scalability_data_ff[DATAKeys.path]}/analysis'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_diag_par, speedup_diag, cost_diag, efficiency_diag, runtime_tria_par, speedup_tria, cost_tria, efficiency_tria = computeMetrics(weak_scalability_data_mpi)\n",
    "os.system(f\"mkdir -p {weak_scalability_data_mpi[DATAKeys.path]}\")\n",
    "\n",
    "plot_analysis(\n",
    "    weak_scalability_data_mpi[DATAKeys.processors],\n",
    "    runtime_diag_par,\n",
    "    cost_diag,\n",
    "    speedup_diag,\n",
    "    efficiency_diag,\n",
    "    'ff diagonals',\n",
    "    runtime_tria_par,\n",
    "    cost_tria,\n",
    "    speedup_tria,\n",
    "    efficiency_tria,\n",
    "    'ff triangles',\n",
    "    f'{weak_scalability_data_mpi[DATAKeys.path]}/analysis'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong and Weak scaling of diagonals with ScatterGather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_scalability_data_sg_mpi = []\n",
    "for s in size:\n",
    "    diagonal_seq_runtime = [row[CSVKeys.runtime] for row in diagonal_seq if row[CSVKeys.size] == s]\n",
    "    triangles_seq_runtime = [row[CSVKeys.runtime] for row in triangles_seq if row[CSVKeys.size] == s]\n",
    "    diagonal_par_runtime = [row[CSVKeys.runtime] for row in diagonal_sg_mpi if row[CSVKeys.size] == s]\n",
    "    t_seq = min(min(diagonal_seq_runtime), min(triangles_seq_runtime))\n",
    "    strong_scalability_data_sg_mpi.append({\n",
    "        DATAKeys.processors: processes,\n",
    "        DATAKeys.runtime_diagonal: diagonal_par_runtime,\n",
    "        DATAKeys.T_seq: t_seq,\n",
    "        DATAKeys.path: f'./strong_scalability_plots_sg_mpi/{s}/',\n",
    "        DATAKeys.size: [s] * len(diagonal_par_runtime),\n",
    "    })\n",
    "\n",
    "for strong_scalability_item in strong_scalability_data_sg_mpi:\n",
    "    processors = strong_scalability_item[DATAKeys.processors]\n",
    "    runtime_diag_par = strong_scalability_item[DATAKeys.runtime_diagonal]\n",
    "    T_seq = strong_scalability_item[DATAKeys.T_seq]\n",
    "\n",
    "    speedup_diag = []\n",
    "    if isinstance(T_seq, list):\n",
    "        speedup_diag = [round(t / r, 2) for t, r in zip(T_seq, runtime_diag_par)]\n",
    "    else:\n",
    "        speedup_diag = [round(T_seq / r, 2) for r in runtime_diag_par]\n",
    "\n",
    "    cost_diag = [r * p for r, p in zip(runtime_diag_par, processors)]\n",
    "    efficiency_diag = [round(100 * s / p, 2) for s, p in zip(speedup_diag, processors)]\n",
    "\n",
    "    plot_single_analysis(\n",
    "        strong_scalability_item[DATAKeys.processors],\n",
    "        runtime_diag_par,\n",
    "        cost_diag,\n",
    "        speedup_diag,\n",
    "        efficiency_diag,\n",
    "        'mpi sg diagonals',\n",
    "        f'{strong_scalability_item[DATAKeys.path]}/analysis'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonal_sg_mpi_runtimes = []\n",
    "seq_runtimes = []\n",
    "\n",
    "for s, p in zip(size, processes):\n",
    "\n",
    "    diag_seq_runtime = [runtime[CSVKeys.runtime] for runtime in diagonal_seq if runtime[CSVKeys.size] == s]\n",
    "    tria_seq_runtime = [runtime[CSVKeys.runtime] for runtime in triangles_seq if runtime[CSVKeys.size] == s]\n",
    "    diagonal_sg_mpi_runtime = [runtime[CSVKeys.runtime] for runtime in diagonal_sg_mpi if runtime[CSVKeys.size] == s and runtime[CSVKeys.workers] == p]\n",
    "    print(diagonal_sg_mpi)\n",
    "    print(diagonal_sg_mpi_runtime)\n",
    "    diagonal_sg_mpi_runtimes.append(diagonal_sg_mpi_runtime[0])\n",
    "    seq_runtimes.append(min(min(diag_seq_runtime), min(tria_seq_runtime)))\n",
    "\n",
    "weak_scalability_data_sg_mpi = {\n",
    "    DATAKeys.processors: processes,\n",
    "    DATAKeys.runtime_diagonal: diagonal_sg_mpi_runtimes,\n",
    "    DATAKeys.runtime_triangle: [],\n",
    "    DATAKeys.T_seq: seq_runtimes,\n",
    "    DATAKeys.path: f'./strong_scalability_plots_sg_mpi/',\n",
    "    DATAKeys.size: size\n",
    "}\n",
    "runtime_diag_par, speedup_diag, cost_diag, efficiency_diag, _, _, _, _ = computeMetrics(weak_scalability_data_sg_mpi)\n",
    "os.system(f\"mkdir -p {weak_scalability_data_sg_mpi[DATAKeys.path]}\")\n",
    "plot_single_analysis(\n",
    "    weak_scalability_data_sg_mpi[DATAKeys.processors],\n",
    "    runtime_diag_par,\n",
    "    cost_diag,\n",
    "    speedup_diag,\n",
    "    efficiency_diag,\n",
    "    'mpi sg diagonals',\n",
    "    f'{weak_scalability_data_sg_mpi[DATAKeys.path]}/analysis'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
